![图片 1](https://github.com/user-attachments/assets/55ee4801-896a-4ce1-99f4-5a3c90267d4f)![图片 1](https://github.com/user-attachments/assets/d7987379-c5b5-432b-9c6e-45f6534d2b1f)# CCFERD
## Complex Context Facial Emotion Recognition Dataset

## Official implementation of our paper:
Visual Prompting in LLMs for Enhancing Emotion Recognition

Vision Large Language Models (VLLMs) are transforming the intersection of computer vision and natural language processing; however, the potential of using visual prompts for emotion recognition in these models remains largely unexplored and untapped. Traditional methods in VLLMs struggle with spatial localization and often discard valuable global context. We propose a novel Set-of-Vision prompting (SoV) approach that enhances zero-shot emotion recognition by using spatial information, such as bounding boxes and facial landmarks, to mark targets precisely. SoV improves accuracy in face count and emotion categorization while preserving the enriched image context. Through comprehensive experimentation and analysis of recent commercial or open-source VLLMs, we evaluate the SoV model's ability to comprehend facial expressions in natural environments. Our findings demonstrate the effectiveness of integrating spatial visual prompts into VLLMs for improving emotion recognition performance.

![图片 1](https://github.com/user-attachments/assets/828264d0-dacf-4471-9814-496c45328b31)

## Dataset Description
The CCFERD dataset consists of a wide range of facial images, each annotated with emotion labels. The images encompass various contexts, including multiple faces per image, different lighting conditions, and varied backgrounds, to simulate real-world conditions. This diversity is intended to enhance the robustness and generalization of emotion recognition models trained on this dataset.

### Example Images
Below are some example images from the CCFERD dataset:
![videos_video_13_image_43](https://github.com/user-attachments/assets/6409b9fb-2625-45f6-a7a6-9ac8c3320f87)
![videos_video_11_image_149](![videos_video_28_image_148](https://github.com/user-attachments/assets/2d69d400-c5a2-437b-832d-c3e0af72060d)
![videos_video_28_image_148](https://github.com/user-attachments/assets/9bc6e891-946c-416d-ae5d-e1d732a70d91)

### Due to anonymous requirement, once the paper is accepted, the actual images of the dataset and python code will be made publicly available.

